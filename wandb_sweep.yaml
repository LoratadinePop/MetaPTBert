program: /home/yzp/project/SimCSE/wandb_train.py
project: MetaPT
method: grid
metric:
  name: loss
  goal: minimize
command:
  - ${env}
  - python
  - ${program}
  - ${args}
  # - "--report_to wandb" # enable logging to W&B
  - "--do_train"
  - "--do_eval"
  - "--overwrite_output_dir"
  - "--load_best_model_at_end"
  - "--fp16"
  - "--mlp_only_train" #
  # - "--frozen" # [True, False]
  - "--meta_prefix" # [True, False] 
  - "--layer_wise" # [True, False]
  - "--do_mlm" # [True, False]
parameters:
  output_dir:
    value: result/bert-base-uncased-nofrozen-nomlm-layerwise-metaprefix
  model_name_or_path:
    value: bert-base-uncased
  train_file: #
    value: data/wiki1m_for_simcse.txt
  seed:
    value: 42
  num_train_epochs:
    value: 1
  per_device_train_batch_size:
    value: 64
  learning_rate:
    values: [3e-5, 5e-3, 3e-2]
  max_seq_length: #
    value: 32
  evaluation_strategy:
    value: steps
  metric_for_best_model:
    value: stsb_spearman
  eval_steps:
    value: 125
  pooler_type:
    value: cls
  temp: 
    value: 0.05
  pre_seq_len:
    values: [4, 8, 12, 16]
  meta_embed_size:
    values: [512, 768]
  layer_embed_size:
    values: [32, 64, 128]
  meta_hidden_size:
    values: [512]
  prefix_hidden_size:
    values: [512]